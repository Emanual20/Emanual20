### Abstract ðŸ‘‹

- ðŸ“– [2024/08/28] Our [Technical Report](https://arxiv.org/abs/2408.15079) BaichuanSEED has been released on arXiv. It introduces an effective universally applicable data processing framework and providing a competitive large language model baseline.

- ðŸ“– \[2024/07/16\] Our full [Paper](https://arxiv.org/abs/2407.13274) "Aligning Explanations for Recommendation with Rating and Feature via Maximizing Mutual Information." has been accepted by [CIKM2024](https://cikm2024.org/)! Congrats Yurou Zhao!

- ðŸ“– \[2024/06/28\] Our Yulan's [Technical Report](https://arxiv.org/abs/2406.19853) "YuLan: An Open-source Large Language Model" has been released! I was served as the lead of data group of pretraining. Weight of [the foundation model](https://huggingface.co/yulan-team/YuLan-Base-12b) and [the chat model](https://huggingface.co/yulan-team/YuLan-Chat-3-12b) is also released.

- ðŸ“– \[2024/03/26\] Our [Paper](https://arxiv.org/abs/2402.16358) "Yulan-GARDEN: An Integrated Data Processing Framework for Pretraining Foundation Models" [\[Code\]](https://github.com/Emanual20/Yulan-GARDEN) has been accepted by the Demo Track of SIGIR2024!

- [My CV(till 2024.7)](https://github.com/Emanual20/Emanual20/blob/main/CV.pdf), [My Information Website (Intro, Pub, Awards)](https://emanual20.github.io)
- ðŸ“« Reach some information about nkucs: [NKUCS.ICU website](https://nkucs.icu), [our development organization](https://github.com/NKUCS-ICU)
